{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bc0ec0ce-9304-4832-8aba-375c8273e7a2",
   "metadata": {},
   "source": [
    "# 9 Virtual Memory\n",
    "\n",
    "Virtual memory is an elegant interaction of hardware exceptions, hardware address translation, main memory, disk files, and kernel software that provides each process with a large, uniform, and private address space.\n",
    "\n",
    "With one clean mechanism, virtual memory provides three important capabilities: \n",
    "1. It uses main memory efficiently by treating it as a cache for an address space stored on disk, keeping only the active areas in main memory and transferring data back and forth between disk and memory as needed.\n",
    "2. It simplifies memory management by providing each process with a uniform address space.\n",
    "3. It protects the address space of each process from corruption by other processes."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23f21209-7004-403b-b444-fce58b1ab3bb",
   "metadata": {},
   "source": [
    "## 9.1 Physical and Virtual Addressing\n",
    "\n",
    "The main memory of a computer system is organized as an array of M contiguous byte-size cells. Each byte has a unique _physical address_ (PA). The first byte has an address of 0, the next byte an address of 1, the next byte an address of 2, and so on. Given this simple organization, the most natural way for a CPU to access memory would be to use physical addresses. We call this approach _physical addressing_. **Figure 9.1** shows an example of physical addressing in the context of a load instruction that reads the 4-byte word starting at physical address 4. When the CPU executes the load instruction, it generates an effective physical address and passes it to main memory over the **memory bus**. The **main memory** fetches the 4-byte word starting at physical address 4 and returns it to the CPU, which stores it in a register.\n",
    "\n",
    "![](asset/ch9/1.png)\n",
    "\n",
    "With virtual addressing, the CPU accesses main memory by generating a _virtual address (VA)_, which is converted to the appropriate physical address before being sent to main memory. The task of converting a virtual address to a physical one is known as _address translation_. Dedicated hardware on the CPU chip called the _memory management unit (MMU)_ translates virtual addresses **on the fly**, using a lookup table stored in main memory whose contents are managed by the operating system.\n",
    "\n",
    "![](asset/ch9/2.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "604fa1b7-efd0-455c-b494-1bbaafd0b76b",
   "metadata": {},
   "source": [
    "## 9.2 Address Spaces\n",
    "\n",
    "An _address space_ is an ordered set of nonnegative integer addresses: $\\{0, 1, 2, ...\\}$\n",
    "\n",
    "If the integers in the address space are consecutive, then we say that it is a _linear address space_. To simplify our discussion, we will always assume linear address spaces. In a system with virtual memory, the CPU generates virtual addresses from an address space of $N = 2^n$ addresses called the _virtual address space_: $\\{0, 1, 2, ..., N\\}$\n",
    "\n",
    "A system also has a _physical address space_ that corresponds to the $M$ bytes of physical memory in the system: $\\{0, 1, 2, ..., M-1\\}$, $M$ is not required to be a power of 2, but to simplify the discussion, we will assume that $M = 2^m$.\n",
    "\n",
    "Each byte of main memory has a virtual address chosen from the virtual address space, and a physical address chosen from the physical address space.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3093cc8b-04c0-403c-829f-68ca409ffb78",
   "metadata": {},
   "source": [
    "## 9.3 VM as a Tool for Caching\n",
    "\n",
    "Conceptually, a virtual memory is organized as an array of $N$ contiguous byte-size\n",
    "cells stored on disk. Each byte has a unique virtual address that serves as an index\n",
    "into the array. The contents of the array on disk are cached in main memory. As\n",
    "with any other cache in the memory hierarchy, the data on disk (the lower level)\n",
    "is partitioned into blocks that serve as the transfer units between the disk and\n",
    "the main memory (the upper level). VM systems handle this by partitioning the virtual memory into fixed-size blocks called _virtual pages (VPs)_. Each virtual page is $P = 2^p$ bytes in size. Similarly, physical memory is partitioned into _physical pages (PPs)_, also $P$ bytes in size. (Physical pages are also referred to as _page frames_.)\n",
    "\n",
    "At any point in time, the set of virtual pages is partitioned into three disjoint\n",
    "subsets:\n",
    "* _Unallocated._ Pages that have not yet been allocated (or created) by the VM system. Unallocated blocks do not have any data associated with them, and thus do not occupy any space on disk.\n",
    "* _Cached._ Allocated pages that are currently cached in physical memory.\n",
    "* _Uncached._ Allocated pages that are not cached in physical memory.\n",
    "\n",
    "The example in **Figure 9.3** shows a small virtual memory with eight virtual\n",
    "pages. Virtual pages 0 and 3 have not been allocated yet, and thus do not yet exist\n",
    "on disk. Virtual pages 1, 4, and 6 are cached in physical memory. Pages 2, 5, and 7\n",
    "are allocated but are not currently cached in physical memory.\n",
    "\n",
    "![](asset/ch9/3.png)\n",
    "\n",
    "### 9.3.1 DRAM Cache Organization\n",
    "\n",
    "To help us keep the different caches in the memory hierarchy straight, we will use\n",
    "the term _SRAM cache_ to denote the L1, L2, and L3 cache memories between the\n",
    "CPU and main memory, and the term _DRAM cache_ to denote the VM system’s\n",
    "cache that caches virtual pages in main memory.\n",
    "\n",
    "Because of the large miss penalty and the expense of accessing the first byte from disk, virtual pages tend to be large—typically 4 KB to 2 MB. Due to the large miss penalty, DRAM caches are fully associative; **that is, any virtual page can be placed in any physical page**.\n",
    "\n",
    "The replacement policy on misses also assumes greater importance, because the penalty associated with replacing the wrong virtual page is so high. Thus, operating systems use much more sophisticated replacement algorithms for DRAM caches than the hardware does for SRAM caches. Finally, because of the large access time of disk, DRAM caches always use write-back instead of write-through.\n",
    "\n",
    "### 9.3.2 Page Tables\n",
    "\n",
    "As with any cache, the VM system must have some way to determine if a virtual\n",
    "page is cached somewhere in DRAM. If so, the system must determine which\n",
    "physical page it is cached in. If there is a miss, the system must determine where the virtual page is stored on disk, select a victim page in physical memory,\n",
    "and copy the virtual page from disk to DRAM, replacing the victim page.\n",
    "\n",
    "These capabilities are provided by a combination of operating system soft-\n",
    "ware, address translation hardware in the MMU (memory management unit), and\n",
    "a data structure stored in physical memory known as a page table that maps vir-\n",
    "tual pages to physical pages. The address translation hardware reads the page table\n",
    "each time it converts a virtual address to a physical address. The operating system\n",
    "is responsible for maintaining the contents of the page table and transferring pages\n",
    "back and forth between disk and DRAM.\n",
    "\n",
    "**Figure 9.4** shows the basic organization of a page table. A page table is an array\n",
    "of _page table entries (PTEs)_. Each page in the virtual address space has a PTE at\n",
    "a fixed offset in the page table. For our purposes, we will assume that each PTE\n",
    "consists of a valid bit and an n-bit address field. The valid bit indicates whether\n",
    "the virtual page is currently cached in DRAM. If the valid bit is set, the address\n",
    "field indicates the start of the corresponding physical page in DRAM where the\n",
    "virtual page is cached. If the valid bit is not set, then a null address indicates that\n",
    "the virtual page has not yet been allocated. Otherwise, the address points to the\n",
    "start of the virtual page on disk.\n",
    "An important point to notice about **Figure 9.4** is that because the DRAM\n",
    "cache is fully associative, any physical page can contain any virtual page.\n",
    "\n",
    "![](asset/ch9/4.png)\n",
    "\n",
    "### 9.3.3 Page Hits\n",
    "\n",
    "Consider what happens when the CPU reads a word of virtual memory contained in VP 2, which is cached in DRAM (**Figure 9.5**). Using a technique we will describe in detail in **Section 9.6**, the address translation hardware uses the virtual address as an index to locate PTE 2 and read it from memory. Since the valid bit is set, the address translation hardware knows that VP 2 is cached in memory. So it uses the physical memory address in the PTE (which points to the start of the cached page in PP 1) to construct the physical address of the word.\n",
    "\n",
    "![](asset/ch9/5.png)\n",
    "\n",
    "### 9.3.4 Page Faults\n",
    "\n",
    "In virtual memory parlance, a DRAM cache miss is known as a _page fault_. **Figure 9.6** shows the state of our example page table before the fault. The CPU has\n",
    "referenced a word in VP 3, which is not cached in DRAM. The address transla-\n",
    "tion hardware reads PTE 3 from memory, infers from the valid bit that VP 3 is\n",
    "not cached, and triggers a page fault exception.\n",
    "\n",
    "The page fault exception invokes\n",
    "a page fault exception handler in the kernel, which selects a victim page—in this\n",
    "case, VP 4 stored in PP 3. If VP 4 has been modified, then the kernel copies it back\n",
    "to disk. In either case, the kernel modifies the page table entry for VP 4 to reflect\n",
    "the fact that VP 4 is no longer cached in main memory.\n",
    "\n",
    "Next, the kernel copies VP 3 from disk to PP 3 in memory, updates PTE 3,\n",
    "and then returns. When the handler returns, it restarts the faulting instruction,\n",
    "which resends the faulting virtual address to the address translation hardware.\n",
    "But now, VP 3 is cached in main memory, and the page hit is handled normally by\n",
    "the address translation hardware. **Figure 9.7** shows the state of our example page\n",
    "table after the page fault.\n",
    "\n",
    "Virtual memory was invented in the early 1960s, long before the widening\n",
    "CPU-memory gap spawned SRAM caches. As a result, virtual memory systems\n",
    "use a different terminology from SRAM caches, even though many of the ideas\n",
    "are similar. In virtual memory parlance, blocks are known as pages. The activity\n",
    "of transferring a page between disk and memory is known as _swapping or paging_.\n",
    "Pages are _swapped in (paged in)_ from disk to DRAM, and _swapped out (paged\n",
    "out)_ from DRAM to disk. The strategy of waiting until the last moment to swap in a page, when a miss occurs, is known as _demand paging_.\n",
    "\n",
    "### 9.3.5 Allocating Pages\n",
    "\n",
    "**Figure 9.8** shows the effect on our example page table when the operating system\n",
    "allocates a new page of virtual memory—for example, as a result of calling malloc.\n",
    "In the example, VP 5 is allocated by creating room on disk and updating PTE 5\n",
    "to point to the newly created page on disk.\n",
    "\n",
    "![](asset/ch9/6.png)\n",
    "\n",
    "\n",
    "\n",
    "### 9.3.6 Locality to the Rescue Again\n",
    "\n",
    "Although the total number of distinct pages that programs reference during an\n",
    "entire run might exceed the total size of physical memory, the principle of locality\n",
    "promises that at any point in time they will tend to work on a smaller set of active\n",
    "pages known as the _working set_ or _resident set_. After an initial overhead where\n",
    "the working set is paged into memory, subsequent references to the working set\n",
    "result in hits, with no additional disk traffic.\n",
    "\n",
    "As long as our programs have good temporal locality, virtual memory systems\n",
    "work quite well. But of course, not all programs exhibit good temporal locality. If\n",
    "the working set size exceeds the size of physical memory, then the program can\n",
    "produce an unfortunate situation known as _thrashing_, where pages are swapped in\n",
    "and out continuously. Although virtual memory is usually efficient, if a program’s\n",
    "performance slows to a crawl, the wise programmer will consider the possibility\n",
    "that it is thrashing.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55ce81f5-39be-41da-bc1f-6483d7561b81",
   "metadata": {},
   "source": [
    "## 9.4 VM as a Tool for Memory Management\n",
    "\n",
    "Notice that multiple virtual pages can be mapped to\n",
    "the same shared physical page.\n",
    "\n",
    "![](asset/ch9/7.png)\n",
    "\n",
    "The combination of demand paging and separate virtual address spaces has\n",
    "a profound impact on the way that memory is used and managed in a system. In\n",
    "particular, VM simplifies linking and loading, the sharing of code and data, and\n",
    "allocating memory to applications.\n",
    "\n",
    "* _Simplifying linking._ A separate address space allows each process to use the same basic format for its memory image, regardless of where the code and data actually reside in physical memory.\n",
    "\n",
    "* _Simplifying loading._ Virtual memory also makes it easy to load executable and shared object files into memory. To load the `.text` and `.data` sections of an object file into a newly created process, the Linux loader allocates virtual pages for the code and data segments, marks them as invalid (i.e., not cached), and points their page table entries to the appropriate locations in the object file. The interesting point is that the loader never actually copies any data from disk into memory. The data are paged in automatically and on demand by the virtual memory system the first time each page is referenced, either by the CPU when it fetches an instruction or by an executing instruction when it references a memory location.\n",
    "\n",
    "* _Simplifying sharing._ Separate address spaces provide the operating system with a consistent mechanism for managing sharing between user processes and the operating system itself. In general, each process has its own private code, data, heap, and stack areas that are not shared with any other process. In this case, the operating system creates page tables that map the corresponding virtual pages to disjoint physical pages. However, in some instances it is desirable for processes to share code and data. For example, every process must call the same operating system kernel code, and every C program makes calls to routines in the standard C library such as printf. Rather than including separate copies of the kernel and standard C library in each process, the operating system can arrange for multiple processes to share a single copy of this code by mapping the appropriate virtual pages in different processes to the same physical pages.\n",
    "\n",
    "* _Simplifying memory allocation._ Virtual memory provides a simple mechanism\n",
    "for allocating additional memory to user processes. When a program running\n",
    "in a user process requests additional heap space (e.g., as a result of calling\n",
    "`malloc`), the operating system allocates an appropriate number, say, $k$, of\n",
    "contiguous virtual memory pages, and maps them to $k$ arbitrary physical pages\n",
    "located anywhere in physical memory. Because of the way page tables work,\n",
    "there is no need for the operating system to locate $k$ contiguous pages of\n",
    "physical memory. The pages can be scattered randomly in physical memory."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "404e8a09-6f6c-4d10-ace6-6ba1fadcafe0",
   "metadata": {},
   "source": [
    "## 9.5 VM as a Tool for Memory Protection\n",
    "\n",
    "Any modern computer system must provide the means for the operating system\n",
    "to control access to the memory system. A user process should not be allowed to modify its read-only code section. Nor should it be allowed to read or modify\n",
    "any of the code and data structures in the kernel. It should not be allowed to read\n",
    "or write the private memory of other processes, and it should not be allowed to\n",
    "modify any virtual pages that are shared with other processes, unless all parties\n",
    "explicitly allow it (via calls to explicit interprocess communication system calls).\n",
    "\n",
    "As we have seen, providing separate virtual address spaces makes it easy to\n",
    "isolate the private memories of different processes. But the address translation\n",
    "mechanism can be extended in a natural way to provide even finer access control.\n",
    "Since the address translation hardware reads a PTE each time the CPU generates\n",
    "an address, it is straightforward to control access to the contents of a virtual page\n",
    "by adding some additional permission bits to the PTE. **Figure 9.10** shows the\n",
    "general idea.\n",
    "\n",
    "![](asset/ch9/8.png)\n",
    "\n",
    "In this example, we have added three permission bits to each PTE. The SUP bit\n",
    "indicates whether processes must be running in kernel (supervisor) mode to access\n",
    "the page. Processes running in kernel mode can access any page, but processes\n",
    "running in user mode are only allowed to access pages for which SUP is 0. The\n",
    "READ and WRITE bits control read and write access to the page. For example,\n",
    "if process i is running in user mode, then it has permission to read VP 0 and to\n",
    "read or write VP 1. However, it is not allowed to access VP 2.\n",
    "\n",
    "If an instruction violates these permissions, then the CPU triggers a general\n",
    "protection fault that transfers control to an exception handler in the kernel, which\n",
    "sends a SIGSEGV signal to the offending process. Linux shells typically report this\n",
    "exception as a “segmentation fault.”"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55d19a20-173d-455c-948d-a2b6c941ef12",
   "metadata": {},
   "source": [
    "## 9.6 Address Translation\n",
    "\n",
    "![](asset/ch9/9.png)\n",
    "\n",
    "In this section, we are omitting a number of details, especially related to timing, that are important to hardware designers but are beyond our scope. For your\n",
    "reference, **Figure 9.11** summarizes the symbols that we will be using throughout\n",
    "this section.\n",
    "\n",
    "Address translation is a mapping between the elements of an N-\n",
    "element virtual address space (VAS) and an M-element physical address space\n",
    "(PAS).\n",
    "\n",
    "**Figure 9.12** shows how the MMU uses the page table to perform this mapping.\n",
    "A control register in the CPU, the page table base register (PTBR) points to the\n",
    "current page table. The $n$-bit virtual address has two components: a $p$-bit virtual\n",
    "page offset (VPO) and an $(n − p)$-bit virtual page number (VPN). The MMU uses\n",
    "the VPN to select the appropriate PTE. For example, VPN 0 selects PTE 0, VPN 1\n",
    "selects PTE 1, and so on. The corresponding physical address is the concatenation\n",
    "of the physical page number (PPN) from the page table entry and the VPO from\n",
    "the virtual address. **Notice that since the physical and virtual pages are both P\n",
    "bytes, the physical page offset (PPO) is identical to the VPO.**\n",
    "\n",
    "![](asset/ch9/10.png)\n",
    "\n",
    "**Figure 9.13(a)** shows the steps that the CPU hardware performs when there\n",
    "is a page hit.\n",
    "* _Step 1._ The processor generates a virtual address and sends it to the MMU.\n",
    "* _Step 2._ The MMU generates the PTE address and requests it from the cache/\n",
    "main memory.\n",
    "* _Step 3._ The cache/main memory returns the PTE to the MMU.\n",
    "* _Step 4._ The MMU constructs the physical address and sends it to the cache/main\n",
    "memory.\n",
    "* _Step 5._ The cache/main memory returns the requested data word to the pro-\n",
    "cessor.\n",
    "\n",
    "Unlike a page hit, which is handled entirely by hardware, handling a page\n",
    "fault requires cooperation between hardware and the operating system kernel\n",
    "(**Figure 9.13(b)**).\n",
    "\n",
    "* _Steps 1 to 3._ The same as steps 1 to 3 in Figure 9.13(a).\n",
    "* _Step 4._ The valid bit in the PTE is zero, so the MMU triggers an exception,\n",
    "which transfers control in the CPU to a page fault exception handler in\n",
    "the operating system kernel.\n",
    "* _Step 5._ The fault handler identifies a victim page in physical memory, and if that\n",
    "page has been modified, pages it out to disk.\n",
    "* _Step 6._ The fault handler pages in the new page and updates the PTE in memory.\n",
    "* _Step 7._ The fault handler returns to the original process, causing the faulting\n",
    "instruction to be restarted. The CPU resends the offending virtual address\n",
    "to the MMU. Because the virtual page is now cached in physical memory,\n",
    "there is a hit, and after the MMU performs the steps in **Figure 9.13(a)**, the\n",
    "main memory returns the requested word to the processor.\n",
    "\n",
    "![](asset/ch9/11.png)\n",
    "\n",
    "首先，处理器生成 VA (Virtual address)并发送给 MMU (Memory management unit)，虚拟地址去除 VPO (Virtual page offset，同时也等于 Physical page offset) 后便是对应的 VPN (Virtual page number)，根据 VPN 和 page table 的地址可以 生成 PTEA (Page table entries address)。随后 MMU 根据 PTEA 到存储在内存中的 page table 中取得 PTE。PTE 中存储了 physical page number (Cached) or disk address (Not cached)。\n",
    "* 如果 valid bit is set，则储存的是 physical page number，则可以直接生成 PA (Physical address)，从 main memory 中获取 data。__这种情况也被称为 page hit__。\n",
    "* 如果 valid bit is not set 时，分为两种情况，如果此时 PTE 储存值为 NULL，则说明page is not allocated，说明此时程序员是在 access 没有被 allocate 的内存区域，结果自然就是 segfault。正确的方式是，1) 不使用未收集的内存 2) 使用 malloc 等函数先收集内存。\n",
    "* 如果 valid bit is not set 时，PTE 储存值非 NULL，说明此时 PTE 中存储的是 disk address。此时 VP (Virtual page) 未在 main memory 中，__这种情况也被称为 page miss__，会触发内核的 page fault exception handler，handler 会选择一个 main memory 中的 victim page，如果选中的 victim page 已经被 modified，那么内核需要把它写回 disk。原本映射到 victim page 的 PTE 的 valid bit is unset (Uncached)。最后，内核把 disk address 中的数据复制到 victim page 中，set valid bit。\n",
    "\n",
    "### 9.6.1 Integrating Caches and VM\n",
    "\n",
    "In any system that uses both virtual memory and SRAM caches, there is the issue of whether to use virtual or physical addresses to access the SRAM cache. Although a detailed discussion of the trade-offs is beyond our scope here, most systems opt for physical addressing. With physical addressing, it is straightforward for multiple processes to have blocks in the cache at the same time and to share blocks from the same virtual pages. Further, the cache does not have to deal with protection issues, because access rights are checked as part of the address translation process.\n",
    "\n",
    "**Figure 9.14** shows how a physically addressed cache might be integrated with virtual memory. The main idea is that the address translation occurs before the cache lookup. Notice that page table entries can be cached, just like any other data words.\n",
    "\n",
    "![](asset/ch9/12.png)\n",
    "\n",
    "### 9.6.2 Speeding Up Address Translation with a TLB\n",
    "\n",
    "As we have seen, every time the CPU generates a virtual address, the MMU must refer to a PTE in order to translate the virtual address into a physical address. In the worst case, this requires an additional fetch from memory, at a cost of tens to hundreds of cycles. If the PTE happens to be cached in L1, then the cost goes down to a handful of cycles. However, many systems try to eliminate even this cost by including a **small cache of PTEs in the MMU** called a _translation lookaside buffer (TLB)_.\n",
    "\n",
    "![](asset/ch9/13.png)\n",
    "\n",
    "A TLB is a small, virtually addressed cache where each line holds a block\n",
    "consisting of a single PTE. A TLB usually has a high degree of associativity. As shown in **Figure 9.15**, the index and tag fields that are used for set selection and line matching are extracted from the virtual page number in the virtual address. If the TLB has $T = 2^t$ sets, then the _TLB index (TLBI)_ consists of the t least significant bits of the VPN, and the _TLB tag (TLBT)_ consists of the remaining bits in the VPN."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1f1c1db-37c2-40fb-9818-d1b3e81f5cd1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
